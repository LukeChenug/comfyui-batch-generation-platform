#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ComfyUIæ‰¹é‡ç”Ÿå›¾APIæœåŠ¡å™¨
ä¼ä¸šçº§ComfyUI APIå°è£…ï¼Œæ”¯æŒæ‰¹é‡è¿œç¨‹ç”Ÿå›¾

åŠŸèƒ½ç‰¹ç‚¹ï¼š
- ğŸš€ æ‰¹é‡ä»»åŠ¡å¤„ç†
- ğŸ“Š å®æ—¶è¿›åº¦ç›‘æ§  
- ğŸ”„ ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
- ğŸ“ è‡ªåŠ¨æ–‡ä»¶ç®¡ç†
- ğŸ”— RESTful APIæ¥å£
- âš¡ å¼‚æ­¥é«˜æ€§èƒ½

ä½œè€…: AIåŠ©æ‰‹
ç‰ˆæœ¬: 1.0
"""

from fastapi import FastAPI, BackgroundTasks, HTTPException, WebSocket, WebSocketDisconnect, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
from typing import List, Dict, Optional, Any
import asyncio
import aiohttp
import websockets
import json
import uuid
import time
import os
import shutil
from pathlib import Path
import logging
from datetime import datetime
import sqlite3
from contextlib import asynccontextmanager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é…ç½®
COMFYUI_SERVER = "http://117.50.172.15:8188"
COMFYUI_WS = "ws://117.50.172.15:8188/ws"
OUTPUT_DIR = Path("./generated_images")
DB_PATH = "./tasks.db"

# åˆ›å»ºå¿…è¦ç›®å½•
OUTPUT_DIR.mkdir(exist_ok=True)

class GenerationRequest(BaseModel):
    """å•ä¸ªç”Ÿæˆè¯·æ±‚"""
    prompt: str
    negative_prompt: Optional[str] = ""
    width: int = 1024
    height: int = 1024
    steps: int = 8
    cfg: float = 1.0
    seed: Optional[int] = None
    batch_size: int = 1
    batch_name: Optional[str] = None
    input_image: Optional[str] = None  # è¾“å…¥å›¾ç‰‡çš„æ–‡ä»¶å

class BatchRequest(BaseModel):
    """æ‰¹é‡ç”Ÿæˆè¯·æ±‚"""
    requests: List[GenerationRequest]
    batch_name: Optional[str] = None
    priority: int = 0

class TaskStatus(BaseModel):
    """ä»»åŠ¡çŠ¶æ€"""
    task_id: str
    status: str  # pending, running, completed, failed
    progress: float
    message: str
    created_at: str
    completed_at: Optional[str] = None
    result_url: Optional[str] = None
    result_urls: Optional[List[str]] = None  # æ”¯æŒå¤šå¼ å›¾ç‰‡
    error: Optional[str] = None
    request_data: Optional[Dict] = None  # ç”Ÿæˆå‚æ•°

class ComfyUIManager:
    """ComfyUIè¿æ¥ç®¡ç†å™¨"""
    
    def __init__(self):
        self.client_id = str(uuid.uuid4())
        self.session = None
        self.ws = None
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
        if self.ws:
            await self.ws.close()
    
    async def submit_prompt(self, workflow: Dict) -> str:
        """æäº¤å·¥ä½œæµåˆ°ComfyUI"""
        url = f"{COMFYUI_SERVER}/prompt"
        data = {
            "prompt": workflow,
            "client_id": self.client_id
        }
        
        async with self.session.post(url, json=data) as response:
            if response.status != 200:
                raise HTTPException(status_code=500, detail="ComfyUIæäº¤å¤±è´¥")
            
            result = await response.json()
            return result["prompt_id"]
    
    async def get_history(self, prompt_id: str) -> Dict:
        """è·å–ä»»åŠ¡å†å²"""
        url = f"{COMFYUI_SERVER}/history/{prompt_id}"
        
        async with self.session.get(url) as response:
            if response.status != 200:
                return {}
            return await response.json()
    
    async def download_image(self, filename: str, subfolder: str = "", type: str = "output") -> bytes:
        """ä¸‹è½½ç”Ÿæˆçš„å›¾åƒ"""
        url = f"{COMFYUI_SERVER}/view"
        params = {
            "filename": filename,
            "subfolder": subfolder,
            "type": type
        }
        
        async with self.session.get(url, params=params) as response:
            if response.status != 200:
                raise HTTPException(status_code=404, detail="å›¾åƒä¸‹è½½å¤±è´¥")
            return await response.read()
    
    async def upload_image_to_comfyui(self, image_data: bytes, filename: str) -> str:
        """ä¸Šä¼ å›¾ç‰‡åˆ°ComfyUIæœåŠ¡å™¨"""
        url = f"{COMFYUI_SERVER}/upload/image"
        
        # åˆ›å»ºFormData
        data = aiohttp.FormData()
        data.add_field('image', image_data, filename=filename, content_type='image/jpeg')
        data.add_field('overwrite', 'true')
        
        try:
            async with self.session.post(url, data=data) as response:
                if response.status == 200:
                    result = await response.json()
                    logger.info(f"âœ… å›¾ç‰‡ä¸Šä¼ åˆ°ComfyUIæˆåŠŸ: {result}")
                    return result.get('name', filename)
                else:
                    logger.error(f"âŒ ComfyUIå›¾ç‰‡ä¸Šä¼ å¤±è´¥: {response.status}")
                    raise Exception(f"ComfyUIå›¾ç‰‡ä¸Šä¼ å¤±è´¥: {response.status}")
        except Exception as e:
            logger.error(f"âŒ ComfyUIå›¾ç‰‡ä¸Šä¼ å¼‚å¸¸: {e}")
            raise e

class TaskManager:
    """ä»»åŠ¡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.init_database()
        self.active_tasks: Dict[str, TaskStatus] = {}
        self.websocket_connections: List[WebSocket] = []
        self.load_tasks_from_database()  # å¯åŠ¨æ—¶åŠ è½½æ•°æ®åº“ä¸­çš„ä»»åŠ¡
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS tasks (
                task_id TEXT PRIMARY KEY,
                status TEXT NOT NULL,
                progress REAL DEFAULT 0,
                message TEXT DEFAULT '',
                created_at TEXT NOT NULL,
                completed_at TEXT,
                result_url TEXT,
                result_urls TEXT,
                error TEXT,
                request_data TEXT,
                batch_name TEXT
            )
        ''')
        
        # æ£€æŸ¥å¹¶æ·»åŠ result_urlså­—æ®µï¼ˆæ•°æ®åº“è¿ç§»ï¼‰
        try:
            cursor.execute("SELECT result_urls FROM tasks LIMIT 1")
        except sqlite3.OperationalError:
            # å­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ å®ƒ
            cursor.execute("ALTER TABLE tasks ADD COLUMN result_urls TEXT")
            conn.commit()
            logger.info("å·²æ·»åŠ result_urlså­—æ®µåˆ°æ•°æ®åº“")
        
        conn.commit()
        conn.close()
    
    def load_tasks_from_database(self):
        """ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰ä»»åŠ¡åˆ°å†…å­˜"""
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT task_id, status, progress, message, created_at, completed_at, 
                   result_url, result_urls, error, request_data
            FROM tasks
            ORDER BY created_at DESC
            LIMIT 100  -- åªåŠ è½½æœ€è¿‘100ä¸ªä»»åŠ¡é¿å…å†…å­˜è¿‡è½½
        ''')
        
        for row in cursor.fetchall():
            task_id, status, progress, message, created_at, completed_at, result_url, result_urls_json, error, request_data_json = row
            
            # è§£æresult_urls JSON
            result_urls = None
            if result_urls_json:
                try:
                    result_urls = json.loads(result_urls_json)
                except json.JSONDecodeError:
                    logger.warning(f"æ— æ³•è§£æä»»åŠ¡ {task_id} çš„result_urls JSON: {result_urls_json}")
            
            # è§£ærequest_data JSON
            request_data = None
            if request_data_json:
                try:
                    request_data = json.loads(request_data_json)
                except json.JSONDecodeError:
                    logger.warning(f"æ— æ³•è§£æä»»åŠ¡ {task_id} çš„request_data JSON: {request_data_json}")
            
            # åˆ›å»ºTaskStatuså¯¹è±¡
            task = TaskStatus(
                task_id=task_id,
                status=status,
                progress=progress,
                message=message or "",
                created_at=created_at,
                completed_at=completed_at,
                result_url=result_url,
                result_urls=result_urls,
                error=error,
                request_data=request_data
            )
            
            self.active_tasks[task_id] = task
        
        conn.close()
        logger.info(f"ä»æ•°æ®åº“åŠ è½½äº† {len(self.active_tasks)} ä¸ªä»»åŠ¡")
    
    def create_task(self, request_data: Dict, batch_name: Optional[str] = None) -> str:
        """åˆ›å»ºæ–°ä»»åŠ¡"""
        task_id = str(uuid.uuid4())
        now = datetime.now().isoformat()
        
        task = TaskStatus(
            task_id=task_id,
            status="pending",
            progress=0,
            message="ä»»åŠ¡å·²åˆ›å»º",
            created_at=now
        )
        
        self.active_tasks[task_id] = task
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO tasks (task_id, status, progress, message, created_at, request_data, batch_name)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (task_id, "pending", 0, "ä»»åŠ¡å·²åˆ›å»º", now, json.dumps(request_data), batch_name))
        
        conn.commit()
        conn.close()
        
        return task_id
    
    def update_task(self, task_id: str, status: Optional[str] = None, 
                   progress: Optional[float] = None, message: Optional[str] = None,
                   result_url: Optional[str] = None, result_urls: Optional[List[str]] = None,
                   error: Optional[str] = None):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        if task_id not in self.active_tasks:
            return
        
        task = self.active_tasks[task_id]
        
        if status:
            task.status = status
        if progress is not None:
            task.progress = progress
        if message:
            task.message = message
        if result_url:
            task.result_url = result_url
        if result_urls:
            task.result_urls = result_urls
        if error:
            task.error = error
        
        if status in ["completed", "failed"]:
            task.completed_at = datetime.now().isoformat()
        
        # æ›´æ–°æ•°æ®åº“
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # å°†result_urlsè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²å­˜å‚¨
        result_urls_json = json.dumps(task.result_urls) if task.result_urls else None
        
        cursor.execute('''
            UPDATE tasks SET status=?, progress=?, message=?, completed_at=?, result_url=?, error=?, result_urls=?
            WHERE task_id=?
        ''', (task.status, task.progress, task.message, task.completed_at, 
              task.result_url, task.error, result_urls_json, task_id))
        
        conn.commit()
        conn.close()
        
        # é€šçŸ¥WebSocketå®¢æˆ·ç«¯
        asyncio.create_task(self.broadcast_update(task))
    
    async def broadcast_update(self, task: TaskStatus):
        """å¹¿æ’­ä»»åŠ¡æ›´æ–°"""
        if not self.websocket_connections:
            return
        
        message = {
            "type": "task_update",
            "data": task.dict()
        }
        
        disconnected = []
        for ws in self.websocket_connections:
            try:
                await ws.send_text(json.dumps(message))
            except:
                disconnected.append(ws)
        
        # ç§»é™¤æ–­å¼€çš„è¿æ¥
        for ws in disconnected:
            self.websocket_connections.remove(ws)
    
    def get_task(self, task_id: str) -> Optional[TaskStatus]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        return self.active_tasks.get(task_id)
    
    def get_all_tasks(self) -> List[TaskStatus]:
        """è·å–æ‰€æœ‰ä»»åŠ¡"""
        return list(self.active_tasks.values())

def create_workflow(request: GenerationRequest) -> Dict:
    """æ ¹æ®è¯·æ±‚åˆ›å»ºComfyUIå·¥ä½œæµï¼ˆè‡ªé€‚åº”FLUX/Qwenï¼‰"""
    seed = request.seed if request.seed else int(time.time() * 1000000) % 1000000000
    
    # å¦‚æœæ²¡æœ‰è¾“å…¥å›¾ç‰‡ï¼Œä½¿ç”¨Qwenæ–‡ç”Ÿå›¾å·¥ä½œæµ
    if not request.input_image:
        return create_qwen_text_to_image_workflow(request, seed)
    else:
        return create_qwen_workflow(request, seed)

def create_qwen_text_to_image_workflow(request: GenerationRequest, seed: int) -> Dict:
    """åˆ›å»ºQwenæ–‡ç”Ÿå›¾å·¥ä½œæµï¼ˆåŸºäºæ–°JSONé…ç½®ï¼‰"""
    workflow = {
        "3": {
            "inputs": {
                "seed": seed,
                "steps": request.steps,
                "cfg": request.cfg,
                "sampler_name": "euler_cfg_pp",
                "scheduler": "sgm_uniform",
                "denoise": 1,
                "model": ["66", 0],
                "positive": ["6", 0],
                "negative": ["7", 0],
                "latent_image": ["58", 0]
            },
            "class_type": "KSampler",
            "_meta": {"title": "Ké‡‡æ ·å™¨"}
        },
        "6": {
            "inputs": {
                "text": request.prompt,
                "clip": ["38", 0]
            },
            "class_type": "CLIPTextEncode",
            "_meta": {"title": "CLIP Text Encode (Positive Prompt)"}
        },
        "7": {
            "inputs": {
                "text": request.negative_prompt or "å˜å½¢è„¸ï¼Œå¥‡æ€ªäº”å®˜ï¼Œå¤¸å¼ åŠ¨æ¼«ï¼Œå¤§å¤´ï¼Œå¡‘æ–™çš®è‚¤ï¼Œ3Dæ¸²æŸ“ï¼Œè¶…ç°å®ä¸»ä¹‰çš®è‚¤ï¼Œææ€–çœ¼ç¥ï¼Œä½è´¨é‡ï¼Œç•¸å½¢ï¼Œé¢å¤–çš„æ‰‹ï¼Œé¢å¤–çš„æ‰‹æŒ‡ï¼Œå¥‡æ€ªå…‰å½±ï¼Œé¿å…é«˜é¥±å’Œäº®è‰²ï¼Œé¿å…å¡‘æ–™æ„Ÿçš„é²œè‰³é¢œè‰²",
                "clip": ["38", 0]
            },
            "class_type": "CLIPTextEncode",
            "_meta": {"title": "CLIP Text Encode (Negative Prompt)"}
        },
        "8": {
            "inputs": {
                "samples": ["3", 0],
                "vae": ["39", 0]
            },
            "class_type": "VAEDecode",
            "_meta": {"title": "VAEè§£ç "}
        },
        "37": {
            "inputs": {
                "unet_name": "Qwen-Image_ComfyUI/qwen_image_bf16.safetensors",
                "weight_dtype": "default"
            },
            "class_type": "UNETLoader",
            "_meta": {"title": "UNetåŠ è½½å™¨"}
        },
        "38": {
            "inputs": {
                "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
                "type": "qwen_image",
                "device": "default"
            },
            "class_type": "CLIPLoader",
            "_meta": {"title": "åŠ è½½CLIP"}
        },
        "39": {
            "inputs": {
                "vae_name": "qwen_image_vae.safetensors"
            },
            "class_type": "VAELoader",
            "_meta": {"title": "åŠ è½½VAE"}
        },
        "58": {
            "inputs": {
                "width": request.width,
                "height": request.height,
                "batch_size": request.batch_size
            },
            "class_type": "EmptySD3LatentImage",
            "_meta": {"title": "ç©ºLatentå›¾åƒï¼ˆSD3ï¼‰"}
        },
        "60": {
            "inputs": {
                "filename_prefix": "ComfyUI",
                "images": ["8", 0]
            },
            "class_type": "SaveImage",
            "_meta": {"title": "ä¿å­˜å›¾åƒ"}
        },
        "66": {
            "inputs": {
                "shift": 3,
                "model": ["73", 0]
            },
            "class_type": "ModelSamplingAuraFlow",
            "_meta": {"title": "é‡‡æ ·ç®—æ³•ï¼ˆAuraFlowï¼‰"}
        },
        "73": {
            "inputs": {
                "lora_name": "Qwen-Image-Lightning/Qwen-Image-Lightning-8steps-V1.0.safetensors",
                "strength_model": 1,
                "model": ["37", 0]
            },
            "class_type": "LoraLoaderModelOnly",
            "_meta": {"title": "LoRAåŠ è½½å™¨ï¼ˆä»…æ¨¡å‹ï¼‰"}
        }
    }
    return workflow

def create_flux_workflow(request: GenerationRequest, seed: int) -> Dict:
    """åˆ›å»ºFLUXæ–‡ç”Ÿå›¾å·¥ä½œæµ"""
    workflow = {
        "1": {
            "inputs": {
                "seed": seed,
                "steps": request.steps,
                "cfg": request.cfg,
                "sampler_name": "dpmpp_2m_sde",
                "scheduler": "simple", 
                "denoise": 1,
                "model": ["2", 0],
                "positive": ["13", 0],
                "negative": ["4", 0],
                "latent_image": ["5", 0]
            },
            "class_type": "KSampler",
            "_meta": {"title": "Ké‡‡æ ·å™¨"}
        },
        "2": {
            "inputs": {
                "unet_name": "flux1-dev-fp8.safetensors",
                "weight_dtype": "fp8_e4m3fn"
            },
            "class_type": "UNETLoader",
            "_meta": {"title": "UNetåŠ è½½å™¨"}
        },
        "4": {
            "inputs": {
                "text": request.negative_prompt,
                "clip": ["9", 0]
            },
            "class_type": "CLIPTextEncode",
            "_meta": {"title": "CLIPæ–‡æœ¬ç¼–ç "}
        },
        "5": {
            "inputs": {
                "width": request.width,
                "height": request.height,
                "batch_size": request.batch_size
            },
            "class_type": "EmptyLatentImage",
            "_meta": {"title": "ç©ºLatentå›¾åƒ"}
        },
        "6": {
            "inputs": {
                "samples": ["1", 0],
                "vae": ["7", 0]
            },
            "class_type": "VAEDecode",
            "_meta": {"title": "VAEè§£ç "}
        },
        "7": {
            "inputs": {
                "vae_name": "ae.safetensors"
            },
            "class_type": "VAELoader",
            "_meta": {"title": "åŠ è½½VAE"}
        },
        "8": {
            "inputs": {
                "images": ["6", 0]
            },
            "class_type": "PreviewImage",
            "_meta": {"title": "é¢„è§ˆå›¾åƒ"}
        },
        "9": {
            "inputs": {
                "clip_name1": "clip_l.safetensors",
                "clip_name2": "t5xxl_fp8_e4m3fn.safetensors",
                "type": "flux",
                "device": "default"
            },
            "class_type": "DualCLIPLoader",
            "_meta": {"title": "åŒCLIPåŠ è½½å™¨"}
        },
        "13": {
            "inputs": {
                "text": request.prompt,
                "clip": ["9", 0]
            },
            "class_type": "CLIPTextEncode",
            "_meta": {"title": "CLIPæ–‡æœ¬ç¼–ç "}
        }
    }
    return workflow

def create_qwen_workflow(request: GenerationRequest, seed: int) -> Dict:
    """åˆ›å»ºQwenå›¾ç”Ÿå›¾å·¥ä½œæµ"""
    input_image = request.input_image
    
    workflow = {
        "60": {
            "inputs": {
                "filename_prefix": "ComfyUI",
                "images": ["115:8", 0]
            },
            "class_type": "SaveImage",
            "_meta": {"title": "ä¿å­˜å›¾åƒ"}
        },
        "78": {
            "inputs": {
                "image": input_image
            },
            "class_type": "LoadImage",
            "_meta": {"title": "åŠ è½½å›¾åƒ"}
        },
        "115:75": {
            "inputs": {
                "strength": 1,
                "model": ["115:66", 0]
            },
            "class_type": "CFGNorm",
            "_meta": {"title": "CFGNorm"}
        },
        "115:39": {
            "inputs": {
                "vae_name": "qwen_image_vae.safetensors"
            },
            "class_type": "VAELoader",
            "_meta": {"title": "åŠ è½½VAE"}
        },
        "115:38": {
            "inputs": {
                "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
                "type": "qwen_image",
                "device": "default"
            },
            "class_type": "CLIPLoader",
            "_meta": {"title": "åŠ è½½CLIP"}
        },
        "115:37": {
            "inputs": {
                "unet_name": "Qwen-Image-Edit_ComfyUI/qwen_image_edit_2509_fp8_e4m3fn.safetensors",
                "weight_dtype": "default"
            },
            "class_type": "UNETLoader",
            "_meta": {"title": "UNetåŠ è½½å™¨"}
        },
        "115:110": {
            "inputs": {
                "prompt": request.negative_prompt,
                "clip": ["115:38", 0],
                "vae": ["115:39", 0],
                "image1": ["115:93", 0]
            },
            "class_type": "TextEncodeQwenImageEditPlus",
            "_meta": {"title": "TextEncodeQwenImageEditPlus"}
        },
        "115:93": {
            "inputs": {
                "upscale_method": "lanczos",
                "megapixels": 1,
                "image": ["78", 0]
            },
            "class_type": "ImageScaleToTotalPixels",
            "_meta": {"title": "ç¼©æ”¾å›¾åƒï¼ˆåƒç´ ï¼‰"}
        },
        "115:66": {
            "inputs": {
                "shift": 3,
                "model": ["115:89", 0]
            },
            "class_type": "ModelSamplingAuraFlow",
            "_meta": {"title": "é‡‡æ ·ç®—æ³•ï¼ˆAuraFlowï¼‰"}
        },
        "115:8": {
            "inputs": {
                "samples": ["115:3", 0],
                "vae": ["115:39", 0]
            },
            "class_type": "VAEDecode",
            "_meta": {"title": "VAEè§£ç "}
        },
        "115:88": {
            "inputs": {
                "pixels": ["115:93", 0],
                "vae": ["115:39", 0]
            },
            "class_type": "VAEEncode",
            "_meta": {"title": "VAEç¼–ç "}
        },
        "115:112": {
            "inputs": {
                "width": request.width,
                "height": request.height,
                "batch_size": request.batch_size
            },
            "class_type": "EmptySD3LatentImage",
            "_meta": {"title": "ç©ºLatentå›¾åƒï¼ˆSD3ï¼‰"}
        },
        "115:89": {
            "inputs": {
                "lora_name": "Qwen-Image-Lightning/Qwen-Image-Lightning-4steps-V1.0.safetensors",
                "strength_model": 1,
                "model": ["115:37", 0]
            },
            "class_type": "LoraLoaderModelOnly",
            "_meta": {"title": "LoRAåŠ è½½å™¨ï¼ˆä»…æ¨¡å‹ï¼‰"}
        },
        "115:116": {
            "inputs": {
                "images": ["115:8", 0]
            },
            "class_type": "PreviewImage",
            "_meta": {"title": "é¢„è§ˆå›¾åƒ"}
        },
        "115:111": {
            "inputs": {
                "prompt": request.prompt,
                "clip": ["115:38", 0],
                "vae": ["115:39", 0],
                "image1": ["115:93", 0]
            },
            "class_type": "TextEncodeQwenImageEditPlus",
            "_meta": {"title": "TextEncodeQwenImageEditPlus"}
        },
        "115:3": {
            "inputs": {
                "seed": seed,
                "steps": request.steps,
                "cfg": request.cfg,
                "sampler_name": "euler_cfg_pp",
                "scheduler": "sgm_uniform",
                "denoise": 0.8,
                "model": ["115:75", 0],
                "positive": ["115:111", 0],
                "negative": ["115:110", 0],
                "latent_image": ["115:112", 0]
            },
            "class_type": "KSampler",
            "_meta": {"title": "Ké‡‡æ ·å™¨"}
        }
    }
    
    return workflow

async def process_single_task(task_id: str, request: GenerationRequest, task_manager: TaskManager):
    """å¤„ç†å•ä¸ªç”Ÿæˆä»»åŠ¡"""
    try:
        task_manager.update_task(task_id, status="running", progress=5, message="å‡†å¤‡è¾“å…¥æ•°æ®...")
        
        # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•è¯·æ±‚å‚æ•°
        logger.info(f"ğŸ¯ ä»»åŠ¡ {task_id} - è¯·æ±‚å‚æ•°: batch_size={request.batch_size}, å°ºå¯¸={request.width}x{request.height}, input_image={request.input_image}")
        
        # å¦‚æœæœ‰è¾“å…¥å›¾ç‰‡ï¼Œå…ˆä¸Šä¼ åˆ°ComfyUIæœåŠ¡å™¨
        comfyui_image_name = None
        if request.input_image:
            task_manager.update_task(task_id, progress=10, message="ä¸Šä¼ å›¾ç‰‡åˆ°ComfyUI...")
            
            # è¯»å–æœ¬åœ°ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶
            local_image_path = Path("./uploaded_images") / request.input_image
            if local_image_path.exists():
                with open(local_image_path, "rb") as f:
                    image_data = f.read()
                
                async with ComfyUIManager() as comfy:
                    try:
                        comfyui_image_name = await comfy.upload_image_to_comfyui(image_data, request.input_image)
                        logger.info(f"âœ… ä»»åŠ¡ {task_id} - å›¾ç‰‡å·²ä¸Šä¼ åˆ°ComfyUI: {comfyui_image_name}")
                        
                        # æ›´æ–°requestä¸­çš„å›¾ç‰‡åç§°ä¸ºComfyUIä¸­çš„åç§°
                        request.input_image = comfyui_image_name
                    except Exception as e:
                        logger.error(f"âŒ ä»»åŠ¡ {task_id} - ComfyUIå›¾ç‰‡ä¸Šä¼ å¤±è´¥: {e}")
                        task_manager.update_task(task_id, status="failed", error=f"å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {str(e)}")
                        return
            else:
                logger.error(f"âŒ ä»»åŠ¡ {task_id} - æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {local_image_path}")
                task_manager.update_task(task_id, status="failed", error="æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨")
                return
        
        task_manager.update_task(task_id, progress=15, message="åˆ›å»ºå·¥ä½œæµ...")
        
        # åˆ›å»ºå·¥ä½œæµ
        workflow = create_workflow(request)
        
        # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•å·¥ä½œæµå…³é”®èŠ‚ç‚¹
        workflow_type = "Qwenæ–‡ç”Ÿå›¾" if not request.input_image else "Qwenå›¾ç”Ÿå›¾"
        batch_node = '58' if not request.input_image else '115:112'
        output_node = '60'  # æ–°å·¥ä½œæµç»Ÿä¸€ä½¿ç”¨èŠ‚ç‚¹60ä½œä¸ºSaveImageè¾“å‡º
        batch_size_in_workflow = workflow.get(batch_node, {}).get('inputs', {}).get('batch_size', 'N/A')
        
        logger.info(f"ğŸ”§ ä»»åŠ¡ {task_id} - å·¥ä½œæµç±»å‹: {workflow_type}")
        logger.info(f"ğŸ”§ ä»»åŠ¡ {task_id} - æ‰¹é‡èŠ‚ç‚¹({batch_node})çš„batch_size: {batch_size_in_workflow}")
        logger.info(f"ğŸ”§ ä»»åŠ¡ {task_id} - è¾“å‡ºèŠ‚ç‚¹: {output_node} (SaveImage)")
        
        async with ComfyUIManager() as comfy:
            task_manager.update_task(task_id, progress=25, message="æäº¤ä»»åŠ¡åˆ°ComfyUI...")
            
            # æäº¤ä»»åŠ¡
            prompt_id = await comfy.submit_prompt(workflow)
            
            task_manager.update_task(task_id, progress=35, message="ç­‰å¾…ComfyUIå¤„ç†...")
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            max_attempts = 150  # 5åˆ†é’Ÿè¶…æ—¶
            for attempt in range(max_attempts):
                await asyncio.sleep(2)
                
                progress = 35 + (attempt / max_attempts) * 55  # 35% åˆ° 90%
                task_manager.update_task(task_id, progress=progress, message="ComfyUIç”Ÿæˆä¸­...")
                
                history = await comfy.get_history(prompt_id)
                
                if prompt_id in history:
                    task_manager.update_task(task_id, progress=90, message="ä¸‹è½½ç”Ÿæˆç»“æœ...")
                    
                    # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•ComfyUIè¿”å›çš„å®Œæ•´å†å²æ•°æ®
                    logger.info(f"ğŸ“‹ ä»»åŠ¡ {task_id} - ComfyUIå†å²æ•°æ®: {json.dumps(history[prompt_id], indent=2, ensure_ascii=False)}")
                    
                    # è·å–ç”Ÿæˆçš„å›¾åƒï¼ˆæ”¯æŒå¤šå¼ ï¼‰- è‡ªé€‚åº”ä¸åŒå·¥ä½œæµ
                    outputs = history[prompt_id]["outputs"]
                    
                    # å°è¯•ä¸åŒçš„è¾“å‡ºèŠ‚ç‚¹
                    images = None
                    output_node = None
                    
                    if "60" in outputs and outputs["60"]["images"]:
                        # Qwenå·¥ä½œæµSaveImageè¾“å‡ºèŠ‚ç‚¹ï¼ˆæ–°é…ç½®ï¼‰
                        images = outputs["60"]["images"]
                        output_node = "60"
                    elif "8" in outputs and outputs["8"]["images"]:
                        # å…¼å®¹æ—§çš„Qwenæ–‡ç”Ÿå›¾å·¥ä½œæµè¾“å‡ºèŠ‚ç‚¹
                        images = outputs["8"]["images"]
                        output_node = "8"
                    elif "115:116" in outputs and outputs["115:116"]["images"]:
                        # å…¼å®¹Qwenå›¾ç”Ÿå›¾å·¥ä½œæµè¾“å‡ºèŠ‚ç‚¹
                        images = outputs["115:116"]["images"]
                        output_node = "115:116"
                    
                    if images:
                        # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•å›¾åƒæ•°é‡å’Œè¾“å‡ºèŠ‚ç‚¹
                        logger.info(f"ğŸ–¼ï¸ ä»»åŠ¡ {task_id} - ä»èŠ‚ç‚¹{output_node}è·å–åˆ° {len(images)} å¼ å›¾ç‰‡")
                        
                        result_urls = []
                        
                        # å¤„ç†æ‰€æœ‰ç”Ÿæˆçš„å›¾åƒ
                        for i, image_info in enumerate(images):
                            # ä¸‹è½½å›¾åƒ
                            image_data = await comfy.download_image(
                                image_info["filename"], 
                                image_info.get("subfolder", ""),
                                image_info.get("type", "output")
                            )
                            
                            # ä¿å­˜å›¾åƒï¼ˆæ·»åŠ åºå·åŒºåˆ†ï¼‰
                            base_name = image_info['filename'].rsplit('.', 1)[0]
                            extension = image_info['filename'].rsplit('.', 1)[1] if '.' in image_info['filename'] else 'png'
                            filename = f"{task_id}_{base_name}_{i+1:02d}.{extension}"
                            file_path = OUTPUT_DIR / filename
                            
                            with open(file_path, "wb") as f:
                                f.write(image_data)
                            
                            result_urls.append(f"/images/{filename}")
                        
                        # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•ä¿å­˜çš„å›¾ç‰‡URLs
                        logger.info(f"ğŸ’¾ ä»»åŠ¡ {task_id} - ä¿å­˜äº† {len(result_urls)} ä¸ªå›¾ç‰‡URL: {result_urls}")
                        
                        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ï¼ˆåŒ…å«æ‰€æœ‰å›¾ç‰‡URLï¼‰
                        task_manager.update_task(
                            task_id, 
                            status="completed", 
                            progress=100, 
                            message=f"ç”Ÿæˆå®Œæˆ ({len(result_urls)}å¼ å›¾ç‰‡)",
                            result_url=result_urls[0] if result_urls else None,
                            result_urls=result_urls  # æ·»åŠ å¤šå›¾ç‰‡æ”¯æŒ
                        )
                        
                        # è°ƒè¯•æ—¥å¿—ï¼šç¡®è®¤ä»»åŠ¡çŠ¶æ€æ›´æ–°
                        logger.info(f"âœ… ä»»åŠ¡ {task_id} - çŠ¶æ€æ›´æ–°å®Œæˆï¼Œå¤šå›¾URLså·²ä¿å­˜")
                        return
                    else:
                        # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„è¾“å‡ºèŠ‚ç‚¹
                        available_nodes = list(outputs.keys())
                        logger.error(f"âŒ ä»»åŠ¡ {task_id} - æœªæ‰¾åˆ°å›¾åƒè¾“å‡ºèŠ‚ç‚¹ï¼Œå¯ç”¨èŠ‚ç‚¹: {available_nodes}")
                        raise Exception(f"æœªæ‰¾åˆ°ç”Ÿæˆçš„å›¾åƒï¼Œå¯ç”¨èŠ‚ç‚¹: {available_nodes}")
            
            # è¶…æ—¶
            task_manager.update_task(task_id, status="failed", error="ä»»åŠ¡è¶…æ—¶")
            
    except Exception as e:
        logger.error(f"ä»»åŠ¡ {task_id} å¤„ç†å¤±è´¥: {e}")
        task_manager.update_task(task_id, status="failed", error=str(e))

# å…¨å±€ä»»åŠ¡ç®¡ç†å™¨
task_manager = TaskManager()

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="ComfyUIæ‰¹é‡ç”Ÿå›¾API",
    description="ä¼ä¸šçº§ComfyUI APIå°è£…ï¼Œæ”¯æŒæ‰¹é‡è¿œç¨‹ç”Ÿå›¾",
    version="1.0.0"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é™æ€æ–‡ä»¶æœåŠ¡
app.mount("/images", StaticFiles(directory=str(OUTPUT_DIR)), name="images")

# æ·»åŠ HTMLæ–‡ä»¶æœåŠ¡
from fastapi.responses import FileResponse
import os

@app.get("/batch_generation_dashboard.html")
async def get_dashboard():
    """æä¾›æ‰¹é‡ç”Ÿå›¾ç®¡ç†ç•Œé¢"""
    html_path = os.path.join(os.path.dirname(__file__), "batch_generation_dashboard.html")
    if os.path.exists(html_path):
        return FileResponse(html_path)
    else:
        raise HTTPException(status_code=404, detail="Dashboard file not found")

@app.get("/")
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "message": "ComfyUIæ‰¹é‡ç”Ÿå›¾APIæœåŠ¡",
        "version": "1.0.0",
        "endpoints": {
            "generate": "/generate - å•ä¸ªå›¾åƒç”Ÿæˆ",
            "batch": "/batch - æ‰¹é‡å›¾åƒç”Ÿæˆ", 
            "status": "/status/{task_id} - æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€",
            "tasks": "/tasks - è·å–æ‰€æœ‰ä»»åŠ¡",
            "ws": "/ws - WebSocketå®æ—¶æ›´æ–°"
        }
    }

@app.post("/upload_image")
async def upload_image(file: UploadFile = File(...)):
    """ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶"""
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å¿…é¡»æ˜¯å›¾ç‰‡æ ¼å¼")
        
        # åˆ›å»ºä¸Šä¼ ç›®å½•
        upload_dir = Path("./uploaded_images")
        upload_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜æ–‡ä»¶
        file_extension = file.filename.split('.')[-1] if '.' in file.filename else 'png'
        saved_filename = f"{int(time.time() * 1000)}.{file_extension}"
        file_path = upload_dir / saved_filename
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        return {"filename": saved_filename, "path": str(file_path)}
        
    except Exception as e:
        logger.error(f"å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {str(e)}")

@app.post("/generate")
async def generate_single(request: GenerationRequest, background_tasks: BackgroundTasks):
    """å•ä¸ªå›¾åƒç”Ÿæˆ"""
    task_id = task_manager.create_task(request.dict(), request.batch_name)
    
    # åå°å¤„ç†ä»»åŠ¡
    background_tasks.add_task(process_single_task, task_id, request, task_manager)
    
    return {"task_id": task_id, "message": "ä»»åŠ¡å·²æäº¤"}

@app.post("/batch")
async def generate_batch(batch_request: BatchRequest, background_tasks: BackgroundTasks):
    """æ‰¹é‡å›¾åƒç”Ÿæˆ"""
    task_ids = []
    batch_name = batch_request.batch_name or f"batch_{int(time.time())}"
    
    for request in batch_request.requests:
        request.batch_name = batch_name
        task_id = task_manager.create_task(request.dict(), batch_name)
        task_ids.append(task_id)
        
        # åå°å¤„ç†ä»»åŠ¡
        background_tasks.add_task(process_single_task, task_id, request, task_manager)
        
        # æ·»åŠ å°å»¶è¿Ÿé¿å…æœåŠ¡å™¨å‹åŠ›è¿‡å¤§
        await asyncio.sleep(0.1)
    
    return {
        "batch_name": batch_name,
        "task_ids": task_ids,
        "message": f"å·²æäº¤ {len(task_ids)} ä¸ªä»»åŠ¡"
    }

@app.get("/status/{task_id}")
async def get_task_status(task_id: str):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")
    
    return task

@app.get("/tasks")
async def get_all_tasks():
    """è·å–æ‰€æœ‰ä»»åŠ¡"""
    return {"tasks": task_manager.get_all_tasks()}

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocketå®æ—¶æ›´æ–°"""
    await websocket.accept()
    task_manager.websocket_connections.append(websocket)
    
    try:
        while True:
            await websocket.receive_text()
    except WebSocketDisconnect:
        task_manager.websocket_connections.remove(websocket)

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{COMFYUI_SERVER}/system_stats", timeout=5) as response:
                comfyui_status = "online" if response.status == 200 else "offline"
    except:
        comfyui_status = "offline"
    
    return {
        "api_server": "online",
        "comfyui_server": comfyui_status,
        "active_tasks": len(task_manager.active_tasks)
    }

if __name__ == "__main__":
    import uvicorn
    
    print("ğŸš€ å¯åŠ¨ComfyUIæ‰¹é‡ç”Ÿå›¾APIæœåŠ¡å™¨")
    print(f"ğŸ“¡ ComfyUIæœåŠ¡å™¨: {COMFYUI_SERVER}")
    print(f"ğŸ“ å›¾åƒè¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print("ğŸŒ APIæ–‡æ¡£: http://localhost:8001/docs")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8001,
        log_level="info"
    )
